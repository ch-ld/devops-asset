package cmdb

import (
	"api-server/internal/model/cmdb"
	repo "api-server/internal/repository/cmdb"
	"encoding/json"
	"fmt"
	"log"
	"math/rand"
	"sort"
	"strconv"
	"strings"
	"sync"
	"time"

	"gorm.io/datatypes"
)

// MetricsService ä¸»æœºæŒ‡æ ‡ç›‘æ§æœåŠ¡
// è´Ÿè´£æ”¶é›†å’Œç»Ÿè®¡ä¸»æœºçš„CPUã€å†…å­˜ã€ç£ç›˜ç­‰æŒ‡æ ‡
type MetricsService struct {
	hostRepo    *repo.HostRepository
	metricsChan chan HostMetrics
	collectors  map[uint]*hostCollector
	mu          sync.RWMutex
	stopChan    chan struct{} // æ·»åŠ åœæ­¢ä¿¡å·é€šé“
	stopped     bool          // æ·»åŠ åœæ­¢çŠ¶æ€æ ‡è®°
}

// HostMetrics ä¸»æœºæŒ‡æ ‡æ•°æ®
type HostMetrics struct {
	HostID      uint       `json:"host_id"`
	Timestamp   time.Time  `json:"timestamp"`
	CPUUsage    float64    `json:"cpu_usage"`    // CPUä½¿ç”¨ç‡ (ç™¾åˆ†æ¯”)
	MemoryUsage float64    `json:"memory_usage"` // å†…å­˜ä½¿ç”¨ç‡ (ç™¾åˆ†æ¯”)
	DiskUsage   float64    `json:"disk_usage"`   // ç£ç›˜ä½¿ç”¨ç‡ (ç™¾åˆ†æ¯”)
	LoadAvg     [3]float64 `json:"load_avg"`     // 1åˆ†é’Ÿã€5åˆ†é’Ÿã€15åˆ†é’Ÿç³»ç»Ÿè´Ÿè½½
	NetIO       struct {
		RxBytes int64 `json:"rx_bytes"` // ç½‘ç»œæ¥æ”¶å­—èŠ‚æ•°/ç§’
		TxBytes int64 `json:"tx_bytes"` // ç½‘ç»œå‘é€å­—èŠ‚æ•°/ç§’
	} `json:"net_io"`
	ProcessCount int `json:"process_count"` // è¿›ç¨‹æ•°é‡
}

// hostCollector å•ä¸»æœºæŒ‡æ ‡æ”¶é›†å™¨
type hostCollector struct {
	hostID       uint
	host         *cmdb.Host
	metricsChan  chan<- HostMetrics
	stopChan     chan struct{}
	interval     time.Duration
	lastNetStats struct {
		timestamp time.Time
		rxBytes   int64
		txBytes   int64
	}
}

// NewMetricsService åˆ›å»ºä¸»æœºæŒ‡æ ‡ç›‘æ§æœåŠ¡å®ä¾‹
func NewMetricsService(hostRepo *repo.HostRepository) *MetricsService {
	return &MetricsService{
		hostRepo:    hostRepo,
		metricsChan: make(chan HostMetrics, 100),
		collectors:  make(map[uint]*hostCollector),
		stopChan:    make(chan struct{}),
		stopped:     false,
	}
}

// Start å¯åŠ¨æŒ‡æ ‡ç›‘æ§æœåŠ¡
func (s *MetricsService) Start() error {
	s.mu.Lock()
	defer s.mu.Unlock()

	if s.stopped {
		return fmt.Errorf("metrics service has been stopped")
	}

	// å¯åŠ¨æŒ‡æ ‡å¤„ç†åç¨‹
	go s.processMetrics()

	// åˆå§‹åŒ–å·²å­˜åœ¨ä¸»æœºçš„æŒ‡æ ‡æ”¶é›†å™¨
	hosts, err := s.hostRepo.FindByStatus("running")
	if err != nil {
		return fmt.Errorf("è·å–è¿è¡Œä¸­ä¸»æœºå¤±è´¥: %w", err)
	}

	for _, host := range hosts {
		s.StartHostMonitoring(host.ID)
	}

	return nil
}

// Stop åœæ­¢æŒ‡æ ‡ç›‘æ§æœåŠ¡
func (s *MetricsService) Stop() {
	s.mu.Lock()
	defer s.mu.Unlock()

	if s.stopped {
		return
	}
	s.stopped = true

	log.Println("ğŸ” [MetricsService] Starting graceful shutdown...")

	// 1. é¦–å…ˆåœæ­¢æ‰€æœ‰æ”¶é›†å™¨ï¼ˆè¿™æ ·å°±ä¸ä¼šå†æœ‰æ–°çš„æŒ‡æ ‡äº§ç”Ÿï¼‰
	log.Printf("ğŸ” [MetricsService] Stopping %d host collectors...", len(s.collectors))
	for hostID, collector := range s.collectors {
		log.Printf("ğŸ” [MetricsService] Stopping collector for host %d", hostID)
		select {
		case <-collector.stopChan:
			// å·²ç»å…³é—­
		default:
			close(collector.stopChan)
		}
	}
	s.collectors = make(map[uint]*hostCollector)

	// 2. ç»™ä¸€ç‚¹æ—¶é—´è®©æ­£åœ¨è¿›è¡Œçš„æŒ‡æ ‡æ”¶é›†å®Œæˆ
	time.Sleep(100 * time.Millisecond)

	// 3. å‘é€åœæ­¢ä¿¡å·ç»™processMetrics goroutine
	log.Println("ğŸ” [MetricsService] Sending stop signal to processMetrics...")
	select {
	case <-s.stopChan:
		// å·²ç»å…³é—­
	default:
		close(s.stopChan)
	}

	// 4. ç­‰å¾…ä¸€ä¸‹è®©processMetrics goroutineå¤„ç†å®Œå½“å‰çš„æŒ‡æ ‡
	time.Sleep(100 * time.Millisecond)

	// 5. æœ€åå…³é—­æŒ‡æ ‡é€šé“
	log.Println("ğŸ” [MetricsService] Closing metrics channel...")
	select {
	case <-s.metricsChan:
		// é€šé“å·²ç»å…³é—­æˆ–ä¸ºç©º
	default:
		close(s.metricsChan)
	}

	log.Println("âœ… [MetricsService] Graceful shutdown completed")
}

// StartHostMonitoring å¼€å§‹ç›‘æ§æŒ‡å®šä¸»æœº
func (s *MetricsService) StartHostMonitoring(hostID uint) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	// å¦‚æœå·²ç»åœ¨ç›‘æ§ä¸­ï¼Œå…ˆåœæ­¢
	if collector, exists := s.collectors[hostID]; exists {
		close(collector.stopChan)
		delete(s.collectors, hostID)
	}

	// è·å–ä¸»æœºä¿¡æ¯
	host, err := s.hostRepo.FindByID(hostID)
	if err != nil {
		return fmt.Errorf("è·å–ä¸»æœºä¿¡æ¯å¤±è´¥: %w", err)
	}

	// åˆ›å»ºæ”¶é›†å™¨
	collector := &hostCollector{
		hostID:      hostID,
		host:        host,
		metricsChan: s.metricsChan,
		stopChan:    make(chan struct{}),
		interval:    time.Minute, // é»˜è®¤æ”¶é›†é—´éš”1åˆ†é’Ÿ
	}

	// å­˜å‚¨æ”¶é›†å™¨
	s.collectors[hostID] = collector

	// å¯åŠ¨æ”¶é›†åç¨‹
	go s.runCollector(collector)

	return nil
}

// StopHostMonitoring åœæ­¢ç›‘æ§æŒ‡å®šä¸»æœº
func (s *MetricsService) StopHostMonitoring(hostID uint) {
	s.mu.Lock()
	defer s.mu.Unlock()

	if collector, exists := s.collectors[hostID]; exists {
		close(collector.stopChan)
		delete(s.collectors, hostID)
	}
}

// runCollector è¿è¡Œä¸»æœºæŒ‡æ ‡æ”¶é›†å™¨
func (s *MetricsService) runCollector(collector *hostCollector) {
	ticker := time.NewTicker(collector.interval)
	defer ticker.Stop()

	// ç«‹å³æ”¶é›†ä¸€æ¬¡æŒ‡æ ‡
	s.collectHostMetrics(collector)

	for {
		select {
		case <-collector.stopChan:
			return
		case <-ticker.C:
			s.collectHostMetrics(collector)
		}
	}
}

// collectHostMetrics æ”¶é›†ä¸»æœºæŒ‡æ ‡
func (s *MetricsService) collectHostMetrics(collector *hostCollector) {
	host := collector.host

	// è·³è¿‡æ²¡æœ‰SSHè®¿é—®æƒé™çš„ä¸»æœº
	var ipList []string
	if err := json.Unmarshal(host.PublicIP, &ipList); err != nil || len(ipList) == 0 {
		return
	}

	if host.Username == "" || host.Password == "" {
		return
	}

	// æ„å»ºSSHå‘½ä»¤
	cmd := `
		echo "===CPU==="
		top -bn1 | grep "Cpu(s)" | sed "s/.*, *\([0-9.]*\)%* id.*/\1/" | awk '{print 100 - $1}'
		echo "===MEMORY==="
		free | grep Mem | awk '{print $3/$2 * 100.0}'
		echo "===DISK==="
		df -h / | grep -v Filesystem | awk '{print $5}' | tr -d '%'
		echo "===LOAD==="
		cat /proc/loadavg
		echo "===NET==="
		cat /proc/net/dev | grep -E "eth0|ens|enp" | awk '{print $2, $10}'
		echo "===PROCESS==="
		ps -ef | wc -l
	`

	// æ‰§è¡ŒSSHå‘½ä»¤
	output, err := s.execSSHCommand(host, cmd)
	if err != nil {
		log.Printf("æ”¶é›†ä¸»æœº %d æŒ‡æ ‡å¤±è´¥: %v", host.ID, err)
		return
	}

	// è§£æè¾“å‡º
	metrics, err := s.parseMetricsOutput(output, collector)
	if err != nil {
		log.Printf("è§£æä¸»æœº %d æŒ‡æ ‡å¤±è´¥: %v", host.ID, err)
		return
	}

	// å‘é€æŒ‡æ ‡æ•°æ®
	metrics.HostID = host.ID
	metrics.Timestamp = time.Now()
	collector.metricsChan <- metrics
}

// execSSHCommand æ‰§è¡ŒSSHå‘½ä»¤
func (s *MetricsService) execSSHCommand(host *cmdb.Host, cmd string) (string, error) {
	// ç¤ºä¾‹ä»£ç ï¼Œå®é™…åº”ä½¿ç”¨SSHåº“æ‰§è¡Œå‘½ä»¤
	// è¿™é‡Œç®€åŒ–å®ç°ï¼Œå‡è®¾å·²ç»æœ‰execSSHCommandå‡½æ•°
	return "===CPU===\n25.5\n===MEMORY===\n65.2\n===DISK===\n78\n===LOAD===\n0.52 0.58 0.65 2/352 24685\n===NET===\n1024000 512000\n===PROCESS===\n243", nil
}

// parseMetricsOutput è§£ææŒ‡æ ‡è¾“å‡º
func (s *MetricsService) parseMetricsOutput(output string, collector *hostCollector) (HostMetrics, error) {
	var metrics HostMetrics
	lines := strings.Split(output, "\n")
	var section string

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" {
			continue
		}

		if strings.HasPrefix(line, "===") && strings.HasSuffix(line, "===") {
			section = line
			continue
		}

		switch section {
		case "===CPU===":
			cpu, err := strconv.ParseFloat(line, 64)
			if err != nil {
				return metrics, fmt.Errorf("è§£æCPUä½¿ç”¨ç‡å¤±è´¥: %w", err)
			}
			metrics.CPUUsage = cpu

		case "===MEMORY===":
			mem, err := strconv.ParseFloat(line, 64)
			if err != nil {
				return metrics, fmt.Errorf("è§£æå†…å­˜ä½¿ç”¨ç‡å¤±è´¥: %w", err)
			}
			metrics.MemoryUsage = mem

		case "===DISK===":
			disk, err := strconv.ParseFloat(line, 64)
			if err != nil {
				return metrics, fmt.Errorf("è§£æç£ç›˜ä½¿ç”¨ç‡å¤±è´¥: %w", err)
			}
			metrics.DiskUsage = disk

		case "===LOAD===":
			parts := strings.Fields(line)
			if len(parts) >= 3 {
				for i := 0; i < 3; i++ {
					load, err := strconv.ParseFloat(parts[i], 64)
					if err != nil {
						continue
					}
					metrics.LoadAvg[i] = load
				}
			}

		case "===NET===":
			parts := strings.Fields(line)
			if len(parts) >= 2 {
				rx, _ := strconv.ParseInt(parts[0], 10, 64)
				tx, _ := strconv.ParseInt(parts[1], 10, 64)

				// è®¡ç®—ç½‘ç»œé€Ÿç‡
				now := time.Now()
				if !collector.lastNetStats.timestamp.IsZero() {
					duration := now.Sub(collector.lastNetStats.timestamp).Seconds()
					if duration > 0 {
						metrics.NetIO.RxBytes = int64(float64(rx-collector.lastNetStats.rxBytes) / duration)
						metrics.NetIO.TxBytes = int64(float64(tx-collector.lastNetStats.txBytes) / duration)
					}
				}

				// æ›´æ–°ä¸Šæ¬¡ç»Ÿè®¡
				collector.lastNetStats.timestamp = now
				collector.lastNetStats.rxBytes = rx
				collector.lastNetStats.txBytes = tx
			}

		case "===PROCESS===":
			procs, err := strconv.Atoi(line)
			if err != nil {
				continue
			}
			metrics.ProcessCount = procs
		}
	}

	return metrics, nil
}

// å®Œå–„processMetricsæ–¹æ³•ï¼Œæ·»åŠ å¯¹æŒ‡æ ‡æ•°æ®çš„å­˜å‚¨é€»è¾‘
func (s *MetricsService) processMetrics() {
	for {
		select {
		case <-s.stopChan:
			// æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºå¾ªç¯
			log.Println("MetricsService processMetrics goroutine stopped")
			return
		case metrics, ok := <-s.metricsChan:
			if !ok {
				// é€šé“å·²å…³é—­ï¼Œé€€å‡ºå¾ªç¯
				log.Println("MetricsService metricsChan closed, processMetrics goroutine stopped")
				return
			}

			// ä¿å­˜æŒ‡æ ‡æ•°æ®åˆ°æ•°æ®åº“æˆ–æ—¶åºæ•°æ®åº“
			if err := s.saveMetricsToStorage(metrics); err != nil {
				log.Printf("ä¿å­˜ä¸»æœº %d æŒ‡æ ‡æ•°æ®å¤±è´¥: %v", metrics.HostID, err)
			}

			// æ£€æŸ¥å¼‚å¸¸å€¼å¹¶è§¦å‘å‘Šè­¦
			s.checkMetricsThresholds(metrics)
		}
	}
}

// saveMetricsToStorage ä¿å­˜æŒ‡æ ‡æ•°æ®åˆ°å­˜å‚¨
func (s *MetricsService) saveMetricsToStorage(metrics HostMetrics) error {
	// å®ç°ä¿å­˜é€»è¾‘
	// å¯ä»¥ä¿å­˜åˆ°å…³ç³»å‹æ•°æ®åº“æˆ–æ—¶åºæ•°æ®åº“
	// è¿™é‡Œç®€åŒ–å®ç°ï¼Œä»…æ‰“å°æ—¥å¿—
	metricsJSON, _ := json.Marshal(metrics)
	log.Printf("ä¿å­˜ä¸»æœº %d çš„æŒ‡æ ‡æ•°æ®: %s", metrics.HostID, string(metricsJSON))

	// TODO: å®é™…ç”Ÿäº§ç¯å¢ƒåº”è¯¥å°†æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“
	// ä¾‹å¦‚ä½¿ç”¨influxdbã€prometheusç­‰æ—¶åºæ•°æ®åº“

	return nil
}

// checkMetricsThresholds æ£€æŸ¥æŒ‡æ ‡é˜ˆå€¼å¹¶è§¦å‘å‘Šè­¦
func (s *MetricsService) checkMetricsThresholds(metrics HostMetrics) {
	// CPU ä½¿ç”¨ç‡å‘Šè­¦é˜ˆå€¼
	if metrics.CPUUsage > 90 {
		log.Printf("è­¦å‘Š: ä¸»æœº %d çš„CPUä½¿ç”¨ç‡è¿‡é«˜: %.2f%%", metrics.HostID, metrics.CPUUsage)
		// TODO: è§¦å‘å‘Šè­¦é€šçŸ¥
	}

	// å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦é˜ˆå€¼
	if metrics.MemoryUsage > 90 {
		log.Printf("è­¦å‘Š: ä¸»æœº %d çš„å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: %.2f%%", metrics.HostID, metrics.MemoryUsage)
		// TODO: è§¦å‘å‘Šè­¦é€šçŸ¥
	}

	// ç£ç›˜ä½¿ç”¨ç‡å‘Šè­¦é˜ˆå€¼
	if metrics.DiskUsage > 90 {
		log.Printf("è­¦å‘Š: ä¸»æœº %d çš„ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: %.2f%%", metrics.HostID, metrics.DiskUsage)
		// TODO: è§¦å‘å‘Šè­¦é€šçŸ¥
	}

	// ç³»ç»Ÿè´Ÿè½½å‘Šè­¦é˜ˆå€¼
	if metrics.LoadAvg[0] > float64(5) { // å‡è®¾å•æ ¸CPU
		log.Printf("è­¦å‘Š: ä¸»æœº %d çš„ç³»ç»Ÿè´Ÿè½½è¿‡é«˜: %.2f", metrics.HostID, metrics.LoadAvg[0])
		// TODO: è§¦å‘å‘Šè­¦é€šçŸ¥
	}
}

// GetLatestMetrics è·å–æŒ‡å®šä¸»æœºçš„æœ€æ–°æŒ‡æ ‡
func (s *MetricsService) GetLatestMetrics(hostID uint) (*HostMetrics, error) {
	// å®é™…å®ç°ä¸­ï¼Œåº”è¯¥ä»å­˜å‚¨ä¸­è¯»å–æœ€æ–°æŒ‡æ ‡
	// è¿™é‡Œç®€åŒ–å®ç°ï¼Œç›´æ¥è§¦å‘ä¸€æ¬¡æ”¶é›†å¹¶è¿”å›
	s.mu.RLock()
	collector, exists := s.collectors[hostID]
	s.mu.RUnlock()

	if !exists {
		return nil, fmt.Errorf("ä¸»æœº %d æœªåœ¨ç›‘æ§ä¸­", hostID)
	}

	metricsChan := make(chan HostMetrics, 1)
	collector.metricsChan = metricsChan

	s.collectHostMetrics(collector)

	select {
	case metrics := <-metricsChan:
		return &metrics, nil
	case <-time.After(10 * time.Second):
		return nil, fmt.Errorf("è·å–ä¸»æœº %d æŒ‡æ ‡è¶…æ—¶", hostID)
	}
}

// GetHostMetricsHistory è·å–ä¸»æœºæŒ‡æ ‡å†å²æ•°æ®
func (s *MetricsService) GetHostMetricsHistory(hostID uint, startTime, endTime time.Time, metricType string) ([]HostMetrics, error) {
	// è¿™é‡Œåº”è¯¥ä»å­˜å‚¨ä¸­æŸ¥è¯¢å†å²æ•°æ®
	// ç®€åŒ–å®ç°ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
	history := []HostMetrics{}

	// è®¡ç®—æ—¶é—´ç‚¹æ•°é‡ï¼Œæ¯å°æ—¶ä¸€ä¸ªç‚¹
	hours := int(endTime.Sub(startTime).Hours()) + 1
	if hours <= 0 {
		return history, nil
	}

	// é™åˆ¶æœ€å¤§è¿”å›ç‚¹æ•°
	if hours > 1000 {
		hours = 1000
	}

	// ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
	for i := 0; i < hours; i++ {
		timestamp := startTime.Add(time.Duration(i) * time.Hour)
		metrics := HostMetrics{
			HostID:      hostID,
			Timestamp:   timestamp,
			CPUUsage:    10 + rand.Float64()*50, // 10-60%
			MemoryUsage: 20 + rand.Float64()*60, // 20-80%
			DiskUsage:   30 + rand.Float64()*50, // 30-80%
			LoadAvg:     [3]float64{rand.Float64() * 3, rand.Float64() * 2, rand.Float64() * 1.5},
		}

		// ç½‘ç»œIO
		metrics.NetIO.RxBytes = rand.Int63n(1024 * 1024 * 10) // 0-10MB/s
		metrics.NetIO.TxBytes = rand.Int63n(1024 * 1024 * 5)  // 0-5MB/s

		// è¿›ç¨‹æ•°
		metrics.ProcessCount = 100 + rand.Intn(200) // 100-300ä¸ªè¿›ç¨‹

		// æ ¹æ®metricTypeè¿‡æ»¤
		if metricType != "all" {
			// ä¿æŒæ‰€æœ‰å­—æ®µï¼Œä½†å®é™…å¯ä»¥æ ¹æ®metricTypeè¿”å›ä¸åŒçš„æ•°æ®ç»“æ„
			history = append(history, metrics)
		} else {
			history = append(history, metrics)
		}
	}

	return history, nil
}

// GetOverallMetrics è·å–æ‰€æœ‰ä¸»æœºçš„æ±‡æ€»æŒ‡æ ‡
func (s *MetricsService) GetOverallMetrics() (map[string]interface{}, error) {
	// è·å–æ‰€æœ‰ä¸»æœº
	hosts, err := s.hostRepo.FindAll()
	if err != nil {
		return nil, fmt.Errorf("è·å–ä¸»æœºåˆ—è¡¨å¤±è´¥: %w", err)
	}

	// å‡†å¤‡ç»“æœ
	result := map[string]interface{}{
		"host_count": len(hosts),
		"metrics": map[string]interface{}{
			"cpu_usage_avg":    0.0,
			"memory_usage_avg": 0.0,
			"disk_usage_avg":   0.0,
			"top_cpu_hosts":    []map[string]interface{}{},
			"top_memory_hosts": []map[string]interface{}{},
		},
	}

	// ç»Ÿè®¡æ±‡æ€»ä¿¡æ¯
	var totalCPUUsage, totalMemoryUsage, totalDiskUsage float64
	var hostMetricsCount int

	type hostMetricItem struct {
		HostID uint
		Name   string
		Value  float64
	}

	var cpuUsageList []hostMetricItem
	var memoryUsageList []hostMetricItem

	// éå†æ‰€æœ‰ä¸»æœºï¼Œæ”¶é›†æœ€æ–°æŒ‡æ ‡
	for _, host := range hosts {
		// ç®€åŒ–å®ç°ï¼Œéšæœºç”Ÿæˆæ•°æ®
		// å®é™…åº”ä»å­˜å‚¨ä¸­æŸ¥è¯¢æœ€æ–°æŒ‡æ ‡
		cpuUsage := 10 + rand.Float64()*60
		memoryUsage := 20 + rand.Float64()*70
		diskUsage := 30 + rand.Float64()*60

		totalCPUUsage += cpuUsage
		totalMemoryUsage += memoryUsage
		totalDiskUsage += diskUsage
		hostMetricsCount++

		cpuUsageList = append(cpuUsageList, hostMetricItem{
			HostID: host.ID,
			Name:   host.Name,
			Value:  cpuUsage,
		})

		memoryUsageList = append(memoryUsageList, hostMetricItem{
			HostID: host.ID,
			Name:   host.Name,
			Value:  memoryUsage,
		})
	}

	// è®¡ç®—å¹³å‡å€¼
	if hostMetricsCount > 0 {
		result["metrics"].(map[string]interface{})["cpu_usage_avg"] = totalCPUUsage / float64(hostMetricsCount)
		result["metrics"].(map[string]interface{})["memory_usage_avg"] = totalMemoryUsage / float64(hostMetricsCount)
		result["metrics"].(map[string]interface{})["disk_usage_avg"] = totalDiskUsage / float64(hostMetricsCount)
	}

	// æ’åºCPUä½¿ç”¨ç‡ï¼Œè·å–å‰5å
	sort.Slice(cpuUsageList, func(i, j int) bool {
		return cpuUsageList[i].Value > cpuUsageList[j].Value
	})

	topCPUHosts := []map[string]interface{}{}
	for i := 0; i < 5 && i < len(cpuUsageList); i++ {
		topCPUHosts = append(topCPUHosts, map[string]interface{}{
			"host_id": cpuUsageList[i].HostID,
			"name":    cpuUsageList[i].Name,
			"value":   cpuUsageList[i].Value,
		})
	}
	result["metrics"].(map[string]interface{})["top_cpu_hosts"] = topCPUHosts

	// æ’åºå†…å­˜ä½¿ç”¨ç‡ï¼Œè·å–å‰5å
	sort.Slice(memoryUsageList, func(i, j int) bool {
		return memoryUsageList[i].Value > memoryUsageList[j].Value
	})

	topMemoryHosts := []map[string]interface{}{}
	for i := 0; i < 5 && i < len(memoryUsageList); i++ {
		topMemoryHosts = append(topMemoryHosts, map[string]interface{}{
			"host_id": memoryUsageList[i].HostID,
			"name":    memoryUsageList[i].Name,
			"value":   memoryUsageList[i].Value,
		})
	}
	result["metrics"].(map[string]interface{})["top_memory_hosts"] = topMemoryHosts

	return result, nil
}

// GetHostsResourceUsage è·å–ä¸»æœºèµ„æºä½¿ç”¨æƒ…å†µ
func (s *MetricsService) GetHostsResourceUsage() (map[string]interface{}, error) {
	// è·å–æ‰€æœ‰è¿è¡Œä¸­çš„ä¸»æœº
	hosts, err := s.hostRepo.FindByStatus("running")
	if err != nil {
		return nil, fmt.Errorf("è·å–è¿è¡Œä¸­ä¸»æœºå¤±è´¥: %w", err)
	}

	// æ„å»ºç»“æœæ•°æ®
	result := map[string]interface{}{
		"cpu_usage": map[string]interface{}{
			"avg":   0.0,
			"max":   0.0,
			"min":   0.0,
			"hosts": []map[string]interface{}{},
		},
		"memory_usage": map[string]interface{}{
			"avg":   0.0,
			"max":   0.0,
			"min":   0.0,
			"hosts": []map[string]interface{}{},
		},
		"disk_usage": map[string]interface{}{
			"avg":   0.0,
			"max":   0.0,
			"min":   0.0,
			"hosts": []map[string]interface{}{},
		},
		"load_avg": map[string]interface{}{
			"1min":  0.0,
			"5min":  0.0,
			"15min": 0.0,
		},
	}

	// å¦‚æœæ²¡æœ‰ä¸»æœºï¼Œç›´æ¥è¿”å›ç©ºç»“æœ
	if len(hosts) == 0 {
		return result, nil
	}

	// ç»Ÿè®¡æ•°æ®
	var totalCPU, totalMemory, totalDisk float64
	var maxCPU, maxMemory, maxDisk float64
	var minCPU, minMemory, minDisk = 100.0, 100.0, 100.0
	var totalLoad1, totalLoad5, totalLoad15 float64

	// æ¨¡æ‹Ÿä¸»æœºæŒ‡æ ‡æ•°æ®
	var cpuHostList, memoryHostList, diskHostList []map[string]interface{}

	for _, host := range hosts {
		// ç”ŸæˆéšæœºæŒ‡æ ‡æ•°æ®(åœ¨å®é™…æƒ…å†µä¸‹ï¼Œè¿™äº›æ•°æ®åº”è¯¥æ¥è‡ªç›‘æ§ç³»ç»Ÿ)
		cpuUsage := 20.0 + rand.Float64()*60.0
		memoryUsage := 30.0 + rand.Float64()*50.0
		diskUsage := 40.0 + rand.Float64()*40.0
		load1 := rand.Float64() * 2.0
		load5 := rand.Float64() * 1.5
		load15 := rand.Float64() * 1.0

		// ç´¯åŠ æ€»æ•°
		totalCPU += cpuUsage
		totalMemory += memoryUsage
		totalDisk += diskUsage
		totalLoad1 += load1
		totalLoad5 += load5
		totalLoad15 += load15

		// æ›´æ–°æœ€å¤§å€¼
		if cpuUsage > maxCPU {
			maxCPU = cpuUsage
		}
		if memoryUsage > maxMemory {
			maxMemory = memoryUsage
		}
		if diskUsage > maxDisk {
			maxDisk = diskUsage
		}

		// æ›´æ–°æœ€å°å€¼
		if cpuUsage < minCPU {
			minCPU = cpuUsage
		}
		if memoryUsage < minMemory {
			minMemory = memoryUsage
		}
		if diskUsage < minDisk {
			minDisk = diskUsage
		}

		// æ·»åŠ åˆ°ä¸»æœºåˆ—è¡¨
		hostItem := map[string]interface{}{
			"id":    host.ID,
			"name":  host.Name,
			"value": cpuUsage,
		}
		cpuHostList = append(cpuHostList, hostItem)

		hostItem = map[string]interface{}{
			"id":    host.ID,
			"name":  host.Name,
			"value": memoryUsage,
		}
		memoryHostList = append(memoryHostList, hostItem)

		hostItem = map[string]interface{}{
			"id":    host.ID,
			"name":  host.Name,
			"value": diskUsage,
		}
		diskHostList = append(diskHostList, hostItem)
	}

	hostCount := float64(len(hosts))

	// è®¡ç®—å¹³å‡å€¼
	result["cpu_usage"].(map[string]interface{})["avg"] = totalCPU / hostCount
	result["cpu_usage"].(map[string]interface{})["max"] = maxCPU
	result["cpu_usage"].(map[string]interface{})["min"] = minCPU
	result["cpu_usage"].(map[string]interface{})["hosts"] = cpuHostList

	result["memory_usage"].(map[string]interface{})["avg"] = totalMemory / hostCount
	result["memory_usage"].(map[string]interface{})["max"] = maxMemory
	result["memory_usage"].(map[string]interface{})["min"] = minMemory
	result["memory_usage"].(map[string]interface{})["hosts"] = memoryHostList

	result["disk_usage"].(map[string]interface{})["avg"] = totalDisk / hostCount
	result["disk_usage"].(map[string]interface{})["max"] = maxDisk
	result["disk_usage"].(map[string]interface{})["min"] = minDisk
	result["disk_usage"].(map[string]interface{})["hosts"] = diskHostList

	result["load_avg"].(map[string]interface{})["1min"] = totalLoad1 / hostCount
	result["load_avg"].(map[string]interface{})["5min"] = totalLoad5 / hostCount
	result["load_avg"].(map[string]interface{})["15min"] = totalLoad15 / hostCount

	return result, nil
}

// extractFirstIP ä»JSONå­—ç¬¦ä¸²ä¸­æå–ç¬¬ä¸€ä¸ªIPåœ°å€
func extractFirstIP(jsonStr datatypes.JSON) string {
	var ips []string
	if err := json.Unmarshal([]byte(jsonStr), &ips); err != nil || len(ips) == 0 {
		return ""
	}
	return ips[0]
}
